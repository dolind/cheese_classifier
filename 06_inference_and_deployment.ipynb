{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and getting raedy for deployment\n",
    "Let's check if our models work in inferences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import load_learner\n",
    "\n",
    "# Load the FastAI Learner\n",
    "learn_inf_tiny = load_learner(\"tiny.pkl\")\n",
    "learn_inf_base= load_learner(\"convnext_base.pkl\")\n",
    "learn_inf_resnet = load_learner(\"resnet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Cantal',\n",
       " tensor(4),\n",
       " tensor([9.7780e-05, 9.0306e-06, 2.1395e-05, 1.0606e-05, 9.9840e-01, 1.2682e-07,\n",
       "         4.7644e-04, 1.4753e-06, 9.9773e-06, 4.0509e-06, 2.3105e-05, 8.3267e-05,\n",
       "         8.9159e-05, 2.2647e-06, 3.8224e-06, 4.5492e-07, 2.8718e-04, 2.2553e-06,\n",
       "         7.6010e-07, 3.5029e-04, 2.3085e-07, 1.2567e-04]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf_tiny.predict(\"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Cantal',\n",
       " tensor(4),\n",
       " tensor([1.5877e-06, 5.6175e-05, 1.3185e-06, 4.0135e-06, 9.9739e-01, 1.9972e-06,\n",
       "         1.6469e-03, 1.1616e-05, 1.5650e-04, 2.0251e-05, 1.6810e-05, 3.3364e-04,\n",
       "         1.2042e-05, 1.8571e-06, 7.5011e-06, 5.5109e-07, 1.8472e-04, 2.0955e-06,\n",
       "         1.5077e-05, 8.5131e-05, 1.5477e-07, 4.9878e-05]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf_base.predict(\"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Cantal',\n",
       " tensor(4),\n",
       " tensor([1.2273e-06, 1.0518e-04, 2.1162e-05, 9.5564e-07, 9.9687e-01, 5.3281e-06,\n",
       "         2.2306e-03, 5.5073e-08, 9.4349e-05, 1.3493e-06, 2.2718e-04, 2.3397e-04,\n",
       "         8.0347e-06, 5.4313e-06, 4.4896e-06, 8.3956e-07, 3.2568e-05, 1.5521e-05,\n",
       "         2.5339e-06, 1.2194e-04, 1.5376e-05, 4.0610e-07]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf_resnet.predict(\"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned before, I did not provide a test set. Therefore the models are difficult to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "Of course we want to share our model and not only by posting it on github or huggingface. What we want is a live version of the model.\n",
    "Deployment can either be done via cloud computing or via on-device or edge computing.\n",
    "\n",
    "The used technologies are slightly different.\n",
    "\n",
    "### Cloud based deployment\n",
    "Ml Models can not be evaluated in simple javascript. Usually a server runs a python backend, which provides an endpoint that is only doing the code of the previous section.\n",
    "\n",
    "[Here](https://www.tanishq.ai/blog/posts/2021-11-16-gradio-huggingface.html) is a good tutorial how to get a simple setup running on hugging face.\n",
    "\n",
    "I developed a webcam based app, the code is in the repo.\n",
    "\n",
    "\n",
    "### Edge based deployment\n",
    "The issue with edge based deployment is python. Python is by default not available on mobile. And due to secure concerns it is becoming more and more complex to run stuff like `termux` to get a full blown python installation to run properly.\n",
    "\n",
    "The other two ways are mobile apps and browser based inference. We limit ourselves to browser based, because this is also accesible via desktop.\n",
    "\n",
    "To get a model to run in a web-browser we need to convert it to the onnx format. \n",
    "\n",
    "In this notebook we will evaluate if the inference roughly gives us the same probability. \n",
    "\n",
    "Due to different preprocessing in fast.ai and the manual preprocessing there can be some differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(learn_convnext_tiny.dls.one_batch()[0].shape)  # Get input shape from DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnx) (2.2.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnx) (6.30.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn_inf_resnet.model\n",
    "dummy_input = torch.randn(1, 3, 224, 224)  # Use batch size 1 for export\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    \"model.onnx\", \n",
    "    export_params=True, \n",
    "    opset_version=11, \n",
    "    do_constant_folding=True, \n",
    "    input_names=[\"input\"], \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}  # Allow variable batch size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (1.21.0)\n",
      "Requirement already satisfied: numpy in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: pillow in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (11.1.0)\n",
      "Requirement already satisfied: torchvision in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: coloredlogs in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnxruntime) (6.30.0)\n",
      "Requirement already satisfied: sympy in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: torch==2.5.1 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (75.8.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dominik/Documents/code/fastai/fastbook/.venv/lib/python3.12/site-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime numpy pillow torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Banon', 'Bleu d’Auvergne', 'Brie de Meaux', 'Camembert', 'Cantal', 'Chabichou du Poitou', 'Comté', 'Fourme d’Ambert', 'Gruyere', 'Livarot', 'Manchego', 'Mimolette', 'Munster', 'Neufchâtel', 'Pont-l’Évêque', 'Pélardon', 'Reblochon', 'Roquefort', 'Selles-sur-Cher', 'Tomme de Savoie', 'Valençay', 'Époisses de Bourgogne']\n"
     ]
    }
   ],
   "source": [
    "class_names = learn_inf_resnet.dls.vocab\n",
    "print(class_names)  # List of class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Cantal (Confidence: 0.997614)\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "# Load ONNX model\n",
    "session = ort.InferenceSession(\"model.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).numpy().astype(np.float32)  # Add batch dim and convert to NumPy\n",
    "    return image\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = \"working/which_cheese_cleaned/which_cheese_first/which_cheese/Cantal/0c81aeec-c0a6-421e-844f-3e6e240885a8.jpg\"  # Replace with your image path\n",
    "input_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Run inference\n",
    "outputs = session.run(None, {\"input\": input_tensor})\n",
    "\n",
    "\n",
    "import torch\n",
    "outputs = session.run(None, {\"input\": input_tensor})[0]  # Raw logits\n",
    "probabilities = torch.nn.functional.softmax(torch.tensor(outputs), dim=1)  # Convert to probabilities\n",
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "# Get predicted class index and label\n",
    "predicted_idx = np.argmax(probabilities)\n",
    "predicted_label = class_names[predicted_idx]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label} (Confidence: {probabilities[0][predicted_idx]:.6f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the models are slightly different. But we will try it anyway in deployment."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6811989,
     "sourceId": 10951089,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
